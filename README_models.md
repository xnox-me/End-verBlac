# OpenAI Models Overview

This document provides an overview of OpenAI models including those for generating images and videos.

## Text and Multimodal Models
- **GPT-4.1 series (gpt-4.1, gpt-4.1-mini, gpt-4.1-nano):** Powerful multimodal models supporting text and image inputs with large context windows.
- **GPT-4o and GPT-4o mini:** Multimodal models supporting text, images, and audio inputs and outputs.
- **GPT-4.5 Preview:** Excels at diverse text and image tasks.
- **o-series models:** Specialized for advanced reasoning and problem-solving.
- **Whisper:** Audio transcription and translation.

## Image Generation Models
- **gpt-image-1:** Latest image generation model available via the Images API, capable of creating images across diverse styles with safety guardrails and metadata.
- **GPT-4o Image Generation:** Integrated image generation in GPT-4o, capable of photorealistic and precise image creation, including text rendering and style control.
- **DALLÂ·E 2 (legacy):** Earlier image generation model.

## Video Generation Models
- **Sora:** OpenAI's video generation model that can create videos from text, images, and videos. Currently available via ChatGPT Plus and Pro subscriptions but not as an API.

## Additional Notes
- Pricing varies by model and usage type.
- Some models like GPT-4.5 and Sora are available only through ChatGPT subscriptions.
- Azure OpenAI offers similar models with some variations and additional specialized models.

For more details, please refer to OpenAI's official documentation and announcements.